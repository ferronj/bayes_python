{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A critical tool in the synthetic biology design toolbox is strain screening. \n",
    "We subject libraries of organisms with designed genetic diversity (a mixed population) to a process relevant to the final goal and select hits based on key metrics.\n",
    "on the order of thousands and millions, quantity is chosen over quality. The assays are quick and paired with cell sorting tools.\n",
    "Additional analysis can tie genotypes to the assay results.\n",
    "For example, a library of 10,000 diversity is sorted with a cytometer using a protein binding dye for fluorescence intensity. Higher fluor intensity correlates with higher protein production\n",
    "\n",
    "my work has focussed on libary screens on the order of 10s to 100s. Discrete screening, where individual genotypes are screened separately using the system of choice, present the opposite problem.\n",
    "our measurement is getting closer to the thing we actually care about, product titer, an actual concentration of protein per unit volume or cell count.\n",
    "Often these efforts lead to a production effort, where a compound of choice actually must be manufactured. Economic analysis must include process yields. \n",
    "\n",
    "At this scale, the assays become more expensive and time consuming, and sample replicates are costly.\n",
    "\n",
    "As we move up in scale in high-throughput workflows, the demands on the screening platform remain (screen many strains), but the cost and time to do so becomes prohibitive.\n",
    "Experiments regularly lack replicate samples (N=1?) and resources are spent on candidates that are not improvements over the control. \n",
    "Several times, projects have ended with the question, did we make it better?\n",
    "\n",
    "Bayesian inference was introduced as an alternative to the frequentist methods we were using (hypothesis testing with p-values, confidence intervals, multifactor ANOVA). Is there something in baysian methodology that may provide greater insights into the data we have.\n",
    "\n",
    "Defining the objective of strain screening and problems below...\n",
    "\n",
    "Objective:\n",
    "1. Test a population of targets (enzymes, strain genotypes, proteins, small molecules) to find individuals that exhibit optimal performance indicators. \n",
    "    Binding affinity, production titer (concentration), economics, growth duration, etc.\n",
    "2. Performance indicators at all stage of the process should link as close as possible to the final measurement of interest (reactor yield, performance in the clinic, economics)\n",
    "\n",
    "Questions a screening platform is answering?\n",
    "1. How do I know if I have a hit?\n",
    "    what difference am I trying to detect?\n",
    "    what binding affinity correlates to realistic clinical outcomes? How much material must be made per unit time for the product to be cost effective?\n",
    "2. What is the minimum number of samples necessary to find a hit?\n",
    "    Measurements are costly (time and financially)\n",
    "    multi-armed bandid problem: https://nbviewer.org/github/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter6_Priorities/Ch6_Priors_PyMC2.ipynb\n",
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import arviz as az\n",
    "import pymc as pm\n",
    "import pytensor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "rng = np.random.default_rng(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screening_data = pd.read_csv('data/screening_sample.csv')\n",
    "screening_data = screening_data.dropna()\n",
    "screening_data['Strain ID'] = screening_data['Strain ID'].astype(str)\n",
    "\n",
    "screening_data = screening_data.drop(screening_data.index[(screening_data['Strain Comment'] == 'Negative Control 1')])\n",
    "\n",
    "print(screening_data.dtypes)\n",
    "\n",
    "screening_data = screening_data.drop(screening_data.index[screening_data['Strain Comment'] == 'Negative Control 1'])\n",
    "\n",
    "data_size = len(screening_data)\n",
    "print(f'data length: {data_size}')\n",
    "screening_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = screening_data.sort_values(by=['Strain Comment', 'Strain ID'])\n",
    "\n",
    "sns.catplot(data=plot_data, x='Strain ID', y='Main %', jitter=False, height=3, aspect=2)\n",
    "sns.catplot(data=plot_data, x='Strain ID', y='Main %', hue='Strain Comment', dodge=False, kind='box', height=4, aspect=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(screening_data, x='Main %', hue='Strain Comment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_kde(screening_data['Main %'], label='Screening Data', rug=False)\n",
    "screening_data['Main %'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Setting the model up splitting up the strain IDs\n",
    "strains = pd.Categorical(screening_data['Strain Comment'])\n",
    "model_shape = len(strains.categories)\n",
    "\n",
    "# priors of model parameters mu and sigma\n",
    "mu_m = screening_data['Main %'].mean()\n",
    "mu_sd = screening_data['Main %'].std() * 2\n",
    "\n",
    "sigma_low = 10**-1\n",
    "sigma_high = 30\n",
    "\n",
    "draws = 100\n",
    "chains = 2\n",
    "\n",
    "coords = {\n",
    "    'mu_dim_0': strains.categories,\n",
    "    'sigma_dim_0': strains.categories\n",
    "    }\n",
    "\n",
    "with pm.Model(coords=coords) as model:\n",
    "    mu = pm.Normal('mu', mu=mu_m, sigma=mu_sd, shape=model_shape)\n",
    "    sigma = pm.Uniform('sigma', lower=sigma_low, upper=sigma_high, shape=model_shape)\n",
    "    \n",
    "    main_percent = pm.Normal('Main %', mu=mu[strains.codes], sigma=sigma[strains.codes], observed=screening_data['Main %'])\n",
    "    \n",
    "    idata = pm.sample_prior_predictive()\n",
    "    idata.extend(pm.sample(draws=draws, tune=1000, chains=chains))\n",
    "    pm.sample_posterior_predictive(idata, extend_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.style.use('arviz-darkgrid')\n",
    "az.plot_trace(idata, compact=False, rug=False, divergences=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_ppc(idata, observed=True, mean=True, group='prior', alpha=0.4)\n",
    "\n",
    "az.plot_trace(idata, divergences=None)\n",
    "az.plot_posterior(idata, kind='kde')\n",
    "\n",
    "az.plot_ppc(idata, kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screening_data['Strain ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting control data and experimental strains\n",
    "control_data = screening_data.loc[screening_data['Strain Comment'] == 'Control']\n",
    "exp_data = screening_data.loc[screening_data['Strain Comment'] == 'DoE']\n",
    "\n",
    "#  Setting the model up splitting up the strain IDs\n",
    "exp_strains = pd.Categorical(exp_data['Strain ID'])\n",
    "exp_model_shape = len(exp_strains.categories)\n",
    "\n",
    "# priors of model parameters mu and sigma\n",
    "mu_m = screening_data['Main %'].mean()\n",
    "mu_sd = screening_data['Main %'].std() * 2\n",
    "\n",
    "sigma_low = 10**-1\n",
    "sigma_high = 30\n",
    "\n",
    "draws = 1000\n",
    "chains = 4\n",
    "\n",
    "coords = {\n",
    "    'mu_dim_0': strains.categories,\n",
    "    'sigma_dim_0': strains.categories\n",
    "    }\n",
    "\n",
    "with pm.Model() as model:\n",
    "    mu = pm.Normal('mu', mu=mu_m, sigma=mu_sd, shape=model_shape)\n",
    "    sigma = pm.Uniform('sigma', lower=sigma_low, upper=sigma_high, shape=model_shape)\n",
    "    \n",
    "    main_percent = pm.Normal('Main %', mu=mu[strains.codes], sigma=sigma[strains.codes], observed=screening_data['Main %'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The control data by itself produces a poorly defined distribution. \n",
    "For this first analysis we'll look at the entire popultion as as single distribution to sample from.\n",
    "\n",
    "Next we'll try modeling the control using several distributions and see how that changes the analysis. Basically matching the p-values we are calculating currently"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
